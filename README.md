# üöÄ SurvivorFlow ‚Äì End-to-End MLOps Pipeline for Survival Prediction

SurvivorFlow is a production-grade MLOps project that predicts Titanic passenger survival using a fully automated ML pipeline integrated with monitoring, drift detection, a feature store, and deployment on Render with Redis and Prometheus.

---

## üìå Key Features

- ‚úÖ Data Ingestion from GCP ‚Üí PostgreSQL via Airflow
- üîß ETL Pipeline with custom DAGs
- üß† Model Training using Scikit-learn
- ‚öôÔ∏è Feature Store built with Redis (Docker/Upstash)
- üìä Drift Detection via Alibi-Detect (KSDrift)
- üìà Real-time Monitoring using Prometheus + Grafana
- üåê Flask App for Live Predictions
- üöÄ Deployed on Render with Redis integration

---

## üóÇÔ∏è Project Structure

```
SURVIVERFLOW-main
‚îú‚îÄ‚îÄ app.py                      # Main Flask app
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ .astro/                     # Astro & Airflow configs
‚îú‚îÄ‚îÄ dags/                       # Airflow DAGs
‚îÇ   ‚îî‚îÄ‚îÄ extract_data_from_gcp.py
‚îú‚îÄ‚îÄ src/                        # Core Python modules
‚îÇ   ‚îú‚îÄ‚îÄ data_ingestion.py
‚îÇ   ‚îú‚îÄ‚îÄ data_processing.py
‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.py
‚îÇ   ‚îú‚îÄ‚îÄ feature_store.py
‚îÇ   ‚îî‚îÄ‚îÄ logger.py
‚îú‚îÄ‚îÄ pipeline/                   # Training pipeline script
‚îú‚îÄ‚îÄ artifacts/                  # Saved model + raw data
‚îÇ   ‚îú‚îÄ‚îÄ models/random_forest_model.pkl
‚îú‚îÄ‚îÄ config/                     # Config paths and DB settings
‚îú‚îÄ‚îÄ notebook/                   # Jupyter testing
‚îú‚îÄ‚îÄ prometheus.yml              # Prometheus config
‚îú‚îÄ‚îÄ render.yml                  # Render deployment config
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ setup.py
```

---

## üîÑ End-to-End Pipeline Overview

### 1Ô∏è‚É£ **Data Engineering**
- Raw CSV uploaded to **GCP Bucket**
- **Airflow DAG** extracts ‚Üí transforms ‚Üí loads into **PostgreSQL**
- Verified in **Jupyter notebook**

### 2Ô∏è‚É£ **Feature Store (Redis)**
- Built Redis-based store for batch + real-time
- Integrated with both local Redis (Docker) and Upstash (Render cloud Redis)

### 3Ô∏è‚É£ **Model Training**
- Preprocessed data using `StandardScaler`
- Trained **Random Forest Classifier**
- Features: Age, Fare, Pclass, Title, etc.
- Saved model to `artifacts/models/`

### 4Ô∏è‚É£ **Flask App + Inference**
- User inputs handled via `Flask`
- Features scaled ‚Üí Drift checked ‚Üí Prediction made
- Result shown on `/` route with styling

### 5Ô∏è‚É£ **Drift Detection**
- Implemented **KSDrift (Alibi-Detect)**
- Compares live data to historical reference
- Triggers **Prometheus counter** if drift is detected

### 6Ô∏è‚É£ **Monitoring with Prometheus + Grafana**
- Exposes `/metrics` endpoint
- Tracks:
  - Prediction count
  - Drift count
- Grafana dashboard can be linked

### 7Ô∏è‚É£ **Deployment on Render**
- Dockerized using custom `Dockerfile`
- App hosted on [üåê https://surviverflow-1.onrender.com](https://surviverflow-1.onrender.com)
- Uses `.env` for secrets like `REDIS_URL`

---

## ‚öôÔ∏è Tech Stack

| Layer          | Tools Used                              |
|----------------|------------------------------------------|
| Data Storage   | GCP Bucket, PostgreSQL                   |
| Orchestration  | Airflow (Astro CLI)                      |
| Model Training | Scikit-learn, Pandas, Numpy              |
| Feature Store  | Redis (Docker + Upstash)                 |
| Drift Detect   | Alibi-Detect (KSDrift)                   |
| Monitoring     | Prometheus + Grafana                     |
| App Layer      | Flask, HTML                              |
| Deployment     | Render, Docker                           |

---

## üîß How to Run Locally

1. Clone the repo:
   ```bash
   git clone https://github.com/aimldinesh/MLOPS-SURVIVERFLOW-PROJECT.git
   cd MLOPS-SURVIVERFLOW-PROJECT
   ```

2. Create `.env` file:
   ```
   REDIS_URL=your_upstash_redis_url
   ```

3. Run locally (Flask only):
   ```bash
   python app.py
   ```

4. OR use Docker:
   ```bash
   docker build -t survivorflow-app .
   docker run -p 5000:5000 survivorflow-app
   ```

---

## üåç Deployment (Render)

> Render setup with Docker + Redis service

- Redis connected via `REDIS_URL` from Upstash
- `render.yml` configured with:
```yaml
services:
  - type: web
    name: survivorflow-app
    env: docker
    dockerfilePath: ./Dockerfile
    envVars:
      - key: REDIS_URL
        sync: false  # Set manually in Render dashboard
```

---

## üìà Monitoring Metrics

| Metric            | Description                        |
|-------------------|------------------------------------|
| `prediction_count`| Number of predictions made         |
| `drift_count`     | Number of drift detections         |

Access at `/metrics` endpoint.

---

## ‚úÖ Live App

üëâ [https://surviverflow-1.onrender.com](https://surviverflow-1.onrender.com)

---
### üñºÔ∏è Live Prediction Interface

Below is a glimpse of the live prediction form from the deployed SurvivorFlow application:

#### ‚úÖ Prediction Result: **Likely to Survive**
![Prediction Positive](https://raw.githubusercontent.com/aimldinesh/SURVIVERFLOW/main/Images/Prediction_output/Survive.PNG)

#### ‚ùå Prediction Result: **Likely to Not Survive**
![Prediction Negative](https://raw.githubusercontent.com/aimldinesh/SURVIVERFLOW/main/Images/Prediction_output/Not_Survive.PNG)

---
### üìä Grafana Dashboard ‚Äì Drift Monitoring

Visual representation of real-time drift monitoring using Grafana and Prometheus:

![Grafana Drift Dashboard](https://raw.githubusercontent.com/aimldinesh/SURVIVERFLOW/main/Images/Grafana/grafana_drift_count.PNG)
![Grafana Drift Dashboard](https://github.com/aimldinesh/SURVIVERFLOW/blob/main/Images/Grafana/grafana_prediction_count.PNG)
![Grafana Drift Dashboard](https://github.com/aimldinesh/SURVIVERFLOW/blob/main/Images/Grafana/grafana_drift_count_graph_2.PNG)
![Grafana Drift Dashboard](https://github.com/aimldinesh/SURVIVERFLOW/blob/main/Images/Grafana/grafana_prediction_count_graph_2.PNG)

---

## üì£ Acknowledgements

- Titanic dataset (Kaggle)
- Render, Upstash, Alibi-Detect
- OpenAI/ChatGPT guidance for MLOps setup

---

## üìå TODO (Optional Enhancements)

- Add CI/CD with GitHub Actions
- Add model versioning with DVC or MLflow
- Schedule retraining pipeline
